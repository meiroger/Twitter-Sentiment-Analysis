{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries.\n",
    "\n",
    "datapath is initially set to current directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter file path for data\n",
    "datapath = './'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import operator\n",
    "from copy import copy\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv is first read in, and the columns of interest (first and last) are extracted from the csv file.\n",
    "\n",
    "New binary indicators are made; positive tweets are indicated by 1 and negative tweets are indicated by 0.\n",
    "\n",
    "In the tweets, all letters are made lowercase so that all the words can be compared with stop words. With all words lowercased, weights are also not case sensitive to words that should be the same. Repeated characters with sequences of length 3 or greater are reduced to sequences of length 3 for consistency among the same words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets are then tokenized and stop words are removed. Because there are no emoticons, punctuation is stripped off the ends of each token. Punctuation in the middle of words such as apostrophes are kept to distinguish between different forms of words such as contractions, possessive nouns, and plural nouns. \n",
    "Handles, numerical digits, and URLs are removed as well since they contribute no sentiment. As many unneccessary words are removed as possible, because there are too many words/features and not enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['awww', \"that's\", 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day'], 0), (['upset', \"can't\", 'update', 'facebook', 'texting', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah'], 0), (['dived', 'many', 'times', 'ball', 'managed', 'save', 'rest', 'go', 'bounds'], 0), (['whole', 'body', 'feels', 'itchy', 'like', 'fire'], 0), (['behaving', \"i'm\", 'mad', \"can't\", 'see'], 0), (['whole', 'crew'], 0), (['need', 'hug'], 0), (['hey', 'long', 'time', 'see', 'yes', 'rains', 'bit', 'bit', 'lol', \"i'm\", 'fine', 'thanks', \"how's\"], 0), (['nope'], 0), (['que', 'muera'], 0)]\n"
     ]
    }
   ],
   "source": [
    "# read in csv file\n",
    "csvname = datapath + 'training.1600000.processed.noemoticon.csv'\n",
    "data = open(csvname, \"r\", encoding = \"ISO-8859-1\")\n",
    "csvReader = csv.reader(data)\n",
    "\n",
    "all_data = []\n",
    "for row in csvReader:\n",
    "    y = int(row[0])\n",
    "    # lowercase tweet \n",
    "    x = row[-1].lower()\n",
    "    # extract columns of interest (tweet, sentiment)\n",
    "    # negative and positive indicators converted to 0 and 1\n",
    "    all_data.append((x,max(0,y-3)))\n",
    "        \n",
    "# used to tokenize and remove stop words\n",
    "tknzr = TweetTokenizer(strip_handles=True,reduce_len=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# used to remove digits\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "\n",
    "for n,instance in enumerate(all_data):\n",
    "    tweet = instance[0]\n",
    "    sentiment = instance[1]\n",
    "    # using regular expressions, remove URLs from tweet \n",
    "    tweet = re.sub(r\"http://\\S+\",\"\",tweet)\n",
    "    tweet = re.sub(r\"https://\\S+\",\"\",tweet)\n",
    "    tweet = re.sub(r\"www.\\S+\",\"\",tweet)\n",
    "    tweet = re.sub(r\"\\S+.com[/\\S+]*\",\"\",tweet)\n",
    "    tweet = re.sub(r\"\\S+.org[/\\S+]*\",\"\",tweet)\n",
    "    tweet = re.sub(r\"\\S+.net[/\\S+]*\",\"\",tweet)\n",
    "    # regular expression to remove emails\n",
    "    tweet =re.sub(r\"\\S*@\\S*\\s?\",\"\",tweet)\n",
    "    tokens = tknzr.tokenize(tweet)\n",
    "    # remove punctuation from ends of each token as well as numerical digits\n",
    "    for i, token in enumerate(tokens):\n",
    "        tokens[i] = token.strip(string.punctuation).translate(remove_digits)\n",
    "    # remove stop words and empty strings\n",
    "    tokenized_tweet = [word for word in tokens if (word not in stop_words and word != '')]\n",
    "    # tuples are used so that each instance is immutable\n",
    "    all_data[n] = (tokenized_tweet, sentiment)\n",
    "\n",
    "# verifying tweet tokenization\n",
    "print(all_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into training, validation, and test sets with a 60-10-30 split.\n",
    "Each set has 50% positive examples and 50% negative examples, so that the standard accuracy measure for any model to beat is 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of examples:  1600000\n",
      "total number of postive examples:  800000\n",
      "total number of negative examples:  800000 \n",
      "\n",
      "training set length:  960000\n",
      "(['going', 'back', 'sleep', 'bit', 'sily', 'tired', 'back', 'later', 'bye', 'x'], 1) \n",
      "\n",
      "validation set length:  160000\n",
      "(['must', 'carried', 'style', 'grabbed', 'much', 'attention', \"we'll\", 'keep', 'good', 'work', 'thanks'], 1) \n",
      "\n",
      "testing set length:  480000\n",
      "([\"i'm\", 'seeing', 'th', 'th', 'th', 'meeting', 'th'], 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples = len(all_data)\n",
    "print(\"total number of examples: \", num_examples)\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "# split positive and negative data into separate lists\n",
    "for instance in all_data:\n",
    "    if instance[1] == 1:\n",
    "        pos_data.append(instance)\n",
    "    else:\n",
    "        neg_data.append(instance)\n",
    "num_pos = len(pos_data)\n",
    "num_neg = len(neg_data)\n",
    "print(\"total number of postive examples: \", num_pos)\n",
    "print(\"total number of negative examples: \", num_neg, \"\\n\")\n",
    "\n",
    "# shuffle all data randomly\n",
    "random.shuffle(pos_data)\n",
    "random.shuffle(neg_data)\n",
    "# 60% training set\n",
    "training_set = pos_data[:int(num_pos*.6)] + neg_data[:int(num_neg*.6)]\n",
    "# 10% validataion set\n",
    "validation_set = pos_data[int(num_pos*.6):int(num_pos*.7)] + neg_data[int(num_neg*.6):int(num_neg*.7)]\n",
    "# 30% test set\n",
    "test_set = pos_data[int(num_pos*.7):] + neg_data[int(num_neg*.7):]\n",
    "\n",
    "# verifying 60-30-10 split and randomization\n",
    "print(\"training set length: \", len(training_set))\n",
    "print(training_set[0],\"\\n\")\n",
    "print(\"validation set length: \", len(validation_set))\n",
    "print(validation_set[0],\"\\n\")\n",
    "print(\"testing set length: \", len(test_set))\n",
    "print(test_set[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary of all the word and weight pairs in the training data is created. A dictionary is used instead of numpy arrays due to constant time lookup. During gradient descent, only the weights that are relevant in a given tweet will be updated with a dictionary, which is important with a large dataset. \n",
    "\n",
    "On the other hand, numpy arrays and matrix math scales linearly to the size of the array/matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words: 214846\n",
      "('going', 0.022947521911705793)\n",
      "('back', 0.29408277852456854)\n",
      "('sleep', 0.9634042292479025)\n",
      "('bit', 0.5763543159075529)\n",
      "('sily', 0.23940557851916455)\n",
      "('tired', 0.6376137835582284)\n",
      "('later', 0.5905545519389176)\n",
      "('bye', 0.675338320645524)\n",
      "('x', 0.9971608140212691)\n",
      "('joe', 0.8678967384007304)\n"
     ]
    }
   ],
   "source": [
    "# dictionary of all words present in training data with corresponding weight\n",
    "words = {}\n",
    "for instance in training_set:\n",
    "    for word in instance[0]:\n",
    "        # make unique\n",
    "        if word not in words:\n",
    "            # initialization of random weight from standard normal distribution\n",
    "            words[word] = np.random.rand()\n",
    "        \n",
    "# number of words/features\n",
    "print(\"total number of words:\",len(words))\n",
    "# verifying dictionary of words created correctly\n",
    "iterator = iter(words.items())\n",
    "for i in range(10):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All helper functions for gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(tweet,b,weights):\n",
    "    '''\n",
    "    computes linear combination of input points,\n",
    "    ignores words that haven't been seen in training set\n",
    "    input:\n",
    "        tweet - str, tweet from a row of data\n",
    "        b - float, bias\n",
    "        weights - dict, dictionary of word, weight pairs\n",
    "    output:\n",
    "        model - float, linear combination of WX + b\n",
    "    '''\n",
    "    wx = 0\n",
    "    for word in tweet:\n",
    "        if word not in weights:\n",
    "            # ignores words that haven't been seen in training set\n",
    "            continue\n",
    "        wx += weights[word]\n",
    "    model = b + wx\n",
    "    return model\n",
    "\n",
    "\n",
    "def ridge_norm(weights):\n",
    "    '''\n",
    "    computes squared L2 norm of weights vector\n",
    "    input:\n",
    "        weights - dict, dictionary of word, weight pairs\n",
    "    output:\n",
    "        norm - float, squared L2 norm of weights vector\n",
    "    '''\n",
    "    arr = np.array(list(weights.values()))\n",
    "    norm = (np.linalg.norm(arr))**2\n",
    "    return norm\n",
    "\n",
    "def pos_cost(tweet,reg,b,weights):\n",
    "    '''\n",
    "    computes cost for a positive example \n",
    "    input:\n",
    "        tweet - str, tweet from a row of data\n",
    "        reg - float, ridge penalty value\n",
    "        b - float, bias\n",
    "        weights - dict, dictionary of word, weight pairs\n",
    "    output:\n",
    "        cost - float, cost for a positive example\n",
    "    '''\n",
    "    cost = -np.log(1/(1 + np.exp(-model(tweet,b,weights)))) + (reg/2)*(ridge_norm(weights))\n",
    "    return cost\n",
    "\n",
    "def neg_cost(tweet,reg,b,weights):\n",
    "    '''\n",
    "    computes cost for a negative example \n",
    "    input:\n",
    "        tweet - str, tweet from a row of data\n",
    "        reg - float, ridge penalty value\n",
    "        b - float, bias\n",
    "        weights - dict, dictionary of word, weight pairs\n",
    "    output:\n",
    "        cost - float, cost for a negative example\n",
    "    '''\n",
    "    cost = -np.log(1 - 1/(1 + np.exp(-model(tweet,b,weights)))) + (reg/2)*(ridge_norm(weights))\n",
    "    return cost\n",
    "\n",
    "def plot_cost_histories(cost_history):\n",
    "    '''\n",
    "    plots cost function history plot\n",
    "    input:\n",
    "        cost_history - list, list of costs at every 10% of dataset gone through\n",
    "    output:\n",
    "        None\n",
    "    '''\n",
    "    num_its = len(cost_history)\n",
    "    iterations = np.linspace(1,num_its,num_its)\n",
    "    plt.plot(iterations,cost_history)\n",
    "    plt.title(\"Cost Function History Plot\")\n",
    "    plt.xlabel(\"iterations (every 10% of dataset)\")\n",
    "    plt.ylabel(\"cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent function with cost calculation:\n",
    "\n",
    "The cost function is only calculated every $\\frac{1}{10}th$ of the training set for better time efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent function \n",
    "def gradient_descent_cost(gamma,max_eps,reg,b,w0):\n",
    "    '''\n",
    "    performs binary (ridge) logistic regression with gradient descent \n",
    "    input:\n",
    "        gamma - float, learning rate\n",
    "        max_eps - int, maximum number of epochs\n",
    "        reg - float, ridge penalty value\n",
    "        b - float, bias\n",
    "        w0 - dict, dictionary of word, weight pairs for initial weights\n",
    "    output:\n",
    "        new_weights - dict, dictionary of word, weight pairs for final weights\n",
    "        cost_history - list, list of costs at every 10% of dataset gone through\n",
    "    '''\n",
    "    # copy initial weights\n",
    "    new_weights = copy(w0)\n",
    "    # cost function history container\n",
    "    cost_history = [] \n",
    "\n",
    "    for k in range(max_eps):\n",
    "        # randomly shuffle data at beginning of each epoch\n",
    "        random.shuffle(training_set)\n",
    "        tweet_counter = 0\n",
    "        for instance in training_set:\n",
    "            # remove duplicate words in tweet\n",
    "            tweet = list(set(instance[0]))\n",
    "            sentiment = instance[1]\n",
    "            p = 1/(1 + np.exp(-model(tweet,b,new_weights)))\n",
    "            for word in tweet:\n",
    "                # evaluation of cost function gradient\n",
    "                grad_eval = (p-sentiment) + reg*new_weights[word]\n",
    "                # take gradient descent step, \n",
    "                new_weights[word] = new_weights[word] - gamma*grad_eval  \n",
    "            \n",
    "            tweet_counter += 1\n",
    "            if tweet_counter % (len(training_set)/10) == 0:\n",
    "                # record cost\n",
    "                if sentiment == 1:\n",
    "                    cost = pos_cost(tweet,reg,b,new_weights)\n",
    "                else:\n",
    "                    cost = neg_cost(tweet,reg,b,new_weights)\n",
    "                cost_history.append(cost)      \n",
    "                \n",
    "    return new_weights, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example run of gradient descent with cost calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final cost: 327.90427377169664\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_w, cost_hist = gradient_descent_cost(10**-2,10,10**-2,0,words)\n",
    "plot_cost_histories(cost_hist)  \n",
    "print(\"final cost:\", cost_hist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better time complexity, a gradient descent function without cost calculations is defined for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent function \n",
    "def gradient_descent(gamma,max_eps,reg,b,w0):\n",
    "    '''\n",
    "    performs binary (ridge) logistic regression with gradient descent \n",
    "    input:\n",
    "        gamma - float, learning rate\n",
    "        max_eps - int, maximum number of epochs\n",
    "        reg - float, ridge penalty value\n",
    "        b - float, bias\n",
    "        w0 - dict, dictionary of word, weight pairs for initial weights\n",
    "    output:\n",
    "        new_weights - dict, dictionary of word, weight pairs for final weights\n",
    "    '''\n",
    "    # copy initial weights\n",
    "    new_weights = copy(w0)\n",
    "\n",
    "    for k in range(max_eps):\n",
    "        # randomly shuffle data at beginning of each epoch\n",
    "        random.shuffle(training_set)\n",
    "        tweet_counter = 0\n",
    "        for instance in training_set:\n",
    "            # remove duplicate words in tweet\n",
    "            tweet = list(set(instance[0]))\n",
    "            sentiment = instance[1]\n",
    "            p = 1/(1 + np.exp(-model(tweet,b,new_weights)))\n",
    "            for word in tweet:\n",
    "                # evaluation of cost function gradient\n",
    "                grad_eval = (p-sentiment) + reg*new_weights[word]\n",
    "                # take gradient descent step, \n",
    "                new_weights[word] = new_weights[word] - gamma*grad_eval  \n",
    "            \n",
    "            tweet_counter += 1  \n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Choosing hyperparameters:`\n",
    "\n",
    "Function for obtaining validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(bias,weights):\n",
    "    '''\n",
    "    gets accuracy of predictions of weights on the validation set\n",
    "    input:\n",
    "        bias - float, bias\n",
    "        weights - dict, dictionary of word, weight pairs for initial weights\n",
    "    output:\n",
    "        accuracy - float, validation accuracy\n",
    "    '''\n",
    "    misclassifications = 0\n",
    "    for instance in validation_set:\n",
    "        tweet = instance[0]\n",
    "        sentiment = instance[1]\n",
    "        p = 1/(1 + np.exp(-model(tweet,b,weights)))\n",
    "        p = round(p)\n",
    "        if p != sentiment:\n",
    "            misclassifications += 1\n",
    "    accuracy = 1 - (misclassifications/len(validation_set))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that haven't been seen before are ignored. There's not enough predictive power in any weights given through other methods to an unseen word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #| learning rate| max epochs| ridge penalty| bias| average accuracy\n",
      "1 .       0.001          5           0.01            -0.5    0.7241104166666666\n",
      "2 .       0.001          5           0.01            0    0.7330479166666667\n",
      "3 .       0.001          5           0.01            0.5    0.72935\n",
      "4 .       0.001          5           0.1            -0.5    0.7089520833333335\n",
      "5 .       0.001          5           0.1            0    0.722925\n",
      "6 .       0.001          5           0.1            0.5    0.7174041666666667\n",
      "7 .       0.001          5           1            -0.5    0.6090104166666667\n",
      "8 .       0.001          5           1            0    0.6784145833333334\n",
      "9 .       0.001          5           1            0.5    0.6431104166666666\n",
      "10 .       0.001          7           0.01            -0.5    0.7309791666666667\n",
      "11 .       0.001          7           0.01            0    0.7406125000000001\n",
      "12 .       0.001          7           0.01            0.5    0.738\n",
      "13 .       0.001          7           0.1            -0.5    0.7154458333333333\n",
      "14 .       0.001          7           0.1            0    0.7311083333333332\n",
      "15 .       0.001          7           0.1            0.5    0.72626875\n",
      "16 .       0.001          7           1            -0.5    0.612075\n",
      "17 .       0.001          7           1            0    0.6894374999999999\n",
      "18 .       0.001          7           1            0.5    0.6496479166666668\n",
      "19 .       0.01          5           0.01            -0.5    0.7553479166666666\n",
      "20 .       0.01          5           0.01            0    0.7661708333333334\n",
      "21 .       0.01          5           0.01            0.5    0.7658375\n",
      "22 .       0.01          5           0.1            -0.5    0.7407791666666667\n",
      "23 .       0.01          5           0.1            0    0.7594479166666667\n",
      "24 .       0.01          5           0.1            0.5    0.7562687499999999\n",
      "25 .       0.01          5           1            -0.5    0.6319458333333333\n",
      "26 .       0.01          5           1            0    0.7356625\n",
      "27 .       0.01          5           1            0.5    0.6779479166666667\n",
      "28 .       0.01          7           0.01            -0.5    0.7574895833333333\n",
      "29 .       0.01          7           0.01            0    0.7685583333333333\n",
      "30 .       0.01          7           0.01            0.5    0.76824375\n",
      "31 .       0.01          7           0.1            -0.5    0.7433979166666665\n",
      "32 .       0.01          7           0.1            0    0.7627125\n",
      "33 .       0.01          7           0.1            0.5    0.7595541666666666\n",
      "34 .       0.01          7           1            -0.5    0.6323416666666667\n",
      "35 .       0.01          7           1            0    0.7388979166666667\n",
      "36 .       0.01          7           1            0.5    0.6790333333333334\n",
      "37 .       0.1          5           0.01            -0.5    0.75319375\n",
      "38 .       0.1          5           0.01            0    0.76341875\n",
      "39 .       0.1          5           0.01            0.5    0.76510625\n",
      "40 .       0.1          5           0.1            -0.5    0.7359395833333334\n",
      "41 .       0.1          5           0.1            0    0.7555333333333333\n",
      "42 .       0.1          5           0.1            0.5    0.7544916666666667\n",
      "43 .       0.1          5           1            -0.5    0.63804375\n",
      "44 .       0.1          5           1            0    0.71674375\n",
      "45 .       0.1          5           1            0.5    0.6676229166666667\n",
      "46 .       0.1          7           0.01            -0.5    0.7544041666666667\n",
      "47 .       0.1          7           0.01            0    0.7626520833333333\n",
      "48 .       0.1          7           0.01            0.5    0.7641479166666666\n",
      "49 .       0.1          7           0.1            -0.5    0.7370041666666666\n",
      "50 .       0.1          7           0.1            0    0.7554145833333333\n",
      "51 .       0.1          7           0.1            0.5    0.7545104166666667\n",
      "52 .       0.1          7           1            -0.5    0.6382291666666666\n",
      "53 .       0.1          7           1            0    0.718975\n",
      "54 .       0.1          7           1            0.5    0.67755625\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [10**-3,10**-2,10**-1]\n",
    "max_epochs = [5,7]\n",
    "ridge_penalties = [10**-2,10**-1,10**0]\n",
    "bias = [-0.5,0,0.5]\n",
    "\n",
    "# 1. choose hyperparameters\n",
    "# 2. train model on training_set, record weights\n",
    "# 3. test weights on validation set, record accuracy\n",
    "# 4. train same model 3 times total and get average accuracy\n",
    "# 5. repeat 1-4 for all combinations of hyperparameters\n",
    "accuracies = []\n",
    "model_num = 0\n",
    "print(\"Model #| learning rate| max epochs| ridge penalty| bias| average accuracy\")\n",
    "for learning_rate in learning_rates:\n",
    "    for num in max_epochs:\n",
    "        for ridge_penalty in ridge_penalties:\n",
    "            for b in bias:\n",
    "                validation_accuracy = 0\n",
    "                for i in range(3):\n",
    "                    new_w = gradient_descent(learning_rate,num,ridge_penalty,b,words)\n",
    "                    validation_accuracy += get_accuracy(b,new_w)\n",
    "                avg_acc = validation_accuracy/3\n",
    "                model_num += 1\n",
    "                \n",
    "                accuracies.append((model_num,avg_acc,[learning_rate,num,ridge_penalty,b]))  \n",
    "                print(model_num,\".      \",learning_rate,\"        \",num,\"         \",ridge_penalty,\"          \",b,\"  \",avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters that yielded the best average accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 0.7685583333333333, [0.01, 7, 0.01, 0])\n"
     ]
    }
   ],
   "source": [
    "best_params = max(accuracies, key=lambda x:x[1])\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the highest accuracies appear to be about 76%, parameters that yield validation accuracies > 76% are considered for the best model. New parameters around the values of the best parameters are tested on the validation set again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 0.7661708333333334, [0.01, 5, 0.01, 0])\n",
      "(21, 0.7658375, [0.01, 5, 0.01, 0.5])\n",
      "(29, 0.7685583333333333, [0.01, 7, 0.01, 0])\n",
      "(30, 0.76824375, [0.01, 7, 0.01, 0.5])\n",
      "(32, 0.7627125, [0.01, 7, 0.1, 0])\n",
      "(38, 0.76341875, [0.1, 5, 0.01, 0])\n",
      "(39, 0.76510625, [0.1, 5, 0.01, 0.5])\n",
      "(47, 0.7626520833333333, [0.1, 7, 0.01, 0])\n",
      "(48, 0.7641479166666666, [0.1, 7, 0.01, 0.5])\n"
     ]
    }
   ],
   "source": [
    "highest_accs = [x for x in accuracies if x[1] > 0.76]\n",
    "for params in highest_accs:\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing again on validation set with new parameter values around the best values from the previous test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #| learning rate| max epochs| ridge penalty| bias| average accuracy\n",
      "1 .       0.01          10           0.01            0    0.7709395833333333\n",
      "2 .       0.01          10           0.01            0.25    0.7729520833333333\n",
      "3 .       0.01          10           0.01            0.5    0.7703145833333332\n",
      "4 .       0.01          10           0.025            0    0.7697229166666667\n",
      "5 .       0.01          10           0.025            0.25    0.7717375\n",
      "6 .       0.01          10           0.025            0.5    0.7695500000000001\n",
      "7 .       0.01          10           0.05            0    0.7680979166666667\n",
      "8 .       0.01          10           0.05            0.25    0.7703958333333333\n",
      "9 .       0.01          10           0.05            0.5    0.7666645833333333\n",
      "10 .       0.01          12           0.01            0    0.7718333333333334\n",
      "11 .       0.01          12           0.01            0.25    0.7738770833333334\n",
      "12 .       0.01          12           0.01            0.5    0.7717708333333334\n",
      "13 .       0.01          12           0.025            0    0.7703833333333333\n",
      "14 .       0.01          12           0.025            0.25    0.7728624999999999\n",
      "15 .       0.01          12           0.025            0.5    0.7707895833333334\n",
      "16 .       0.01          12           0.05            0    0.7690020833333334\n",
      "17 .       0.01          12           0.05            0.25    0.7717625\n",
      "18 .       0.01          12           0.05            0.5    0.7679145833333333\n",
      "19 .       0.1          10           0.01            0    0.76273125\n",
      "20 .       0.1          10           0.01            0.25    0.7650041666666666\n",
      "21 .       0.1          10           0.01            0.5    0.7641083333333333\n",
      "22 .       0.1          10           0.025            0    0.7610979166666666\n",
      "23 .       0.1          10           0.025            0.25    0.7637416666666667\n",
      "24 .       0.1          10           0.025            0.5    0.7626312500000001\n",
      "25 .       0.1          10           0.05            0    0.7582000000000001\n",
      "26 .       0.1          10           0.05            0.25    0.7618104166666666\n",
      "27 .       0.1          10           0.05            0.5    0.759175\n",
      "28 .       0.1          12           0.01            0    0.7626333333333334\n",
      "29 .       0.1          12           0.01            0.25    0.7647791666666667\n",
      "30 .       0.1          12           0.01            0.5    0.7651604166666667\n",
      "31 .       0.1          12           0.025            0    0.7617895833333334\n",
      "32 .       0.1          12           0.025            0.25    0.7638895833333333\n",
      "33 .       0.1          12           0.025            0.5    0.7632333333333333\n",
      "34 .       0.1          12           0.05            0    0.7601062499999999\n",
      "35 .       0.1          12           0.05            0.25    0.7611145833333333\n",
      "36 .       0.1          12           0.05            0.5    0.7605958333333334\n"
     ]
    }
   ],
   "source": [
    "learning_rates2 = [10**-2,10**-1]\n",
    "max_epochs2 = [10,12]\n",
    "ridge_penalties2 = [0.01,0.025,0.05]\n",
    "bias2 = [0,0.25,0.5]\n",
    "accuracies2 = []\n",
    "model_num = 0\n",
    "print(\"Model #| learning rate| max epochs| ridge penalty| bias| average accuracy\")\n",
    "for learning_rate in learning_rates2:\n",
    "    for num in max_epochs2:\n",
    "        for ridge_penalty in ridge_penalties2:\n",
    "            for b in bias2:\n",
    "                validation_accuracy = 0\n",
    "                for i in range(3):\n",
    "                    new_w = gradient_descent(learning_rate,num,ridge_penalty,b,words)\n",
    "                    validation_accuracy += get_accuracy(b,new_w)\n",
    "                avg_acc = validation_accuracy/3\n",
    "                model_num += 1\n",
    "                \n",
    "                accuracies2.append((model_num,avg_acc,[learning_rate,num,ridge_penalty,b]))  \n",
    "                print(model_num,\".      \",learning_rate,\"        \",num,\"         \",ridge_penalty,\"          \",b,\"  \",avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters that yielded the best average accuracy for the second validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 0.7738770833333334, [0.01, 12, 0.01, 0.25])\n"
     ]
    }
   ],
   "source": [
    "best_params = max(accuracies2, key=lambda x:x[1])\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at all models that yielded accuracies > 77% to see if there's a trend or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.7709395833333333, [0.01, 10, 0.01, 0])\n",
      "(2, 0.7729520833333333, [0.01, 10, 0.01, 0.25])\n",
      "(3, 0.7703145833333332, [0.01, 10, 0.01, 0.5])\n",
      "(5, 0.7717375, [0.01, 10, 0.025, 0.25])\n",
      "(8, 0.7703958333333333, [0.01, 10, 0.05, 0.25])\n",
      "(10, 0.7718333333333334, [0.01, 12, 0.01, 0])\n",
      "(11, 0.7738770833333334, [0.01, 12, 0.01, 0.25])\n",
      "(12, 0.7717708333333334, [0.01, 12, 0.01, 0.5])\n",
      "(13, 0.7703833333333333, [0.01, 12, 0.025, 0])\n",
      "(14, 0.7728624999999999, [0.01, 12, 0.025, 0.25])\n",
      "(15, 0.7707895833333334, [0.01, 12, 0.025, 0.5])\n",
      "(17, 0.7717625, [0.01, 12, 0.05, 0.25])\n"
     ]
    }
   ],
   "source": [
    "highest_accs = [x for x in accuracies2 if x[1] > 0.77]\n",
    "for params in highest_accs:\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there is no significant difference between running gradient descent with either 10 or 12 epochs, as shown with the flattening of the cost function history plot as number of iterations increase. The best learning rate and ridge penalty appear to be $10^{-2}$. The best bias appears to be between 0 and 0.5 with no significant difference among any of those values. \n",
    "\n",
    "Because there seems to be no significant difference among the values described, the mode of each of the parameters in the cell above are chosen. These parameters also happen to be the parameters of the model with the highest average validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function history plot with the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final cost: 324.95380168522763\n",
      "accuracy: 0.7691875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_w, cost_hist = gradient_descent_cost(10**-2,12,10**-2,0.25,words)\n",
    "plot_cost_histories(cost_hist)  \n",
    "print(\"final cost:\", cost_hist[-1])\n",
    "# validation set accuracy\n",
    "acc = get_accuracy(0.25,best_w)\n",
    "print(\"accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for obtaining test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(bias,weights):\n",
    "    '''\n",
    "    gets accuracy of predictions of weights on the test set\n",
    "    input:\n",
    "        bias - float, bias\n",
    "        weights - dict, dictionary of word, weight pairs for initial weights\n",
    "    output:\n",
    "        test_acc - float, test accuracy\n",
    "    '''\n",
    "    misclassifications = 0\n",
    "    for instance in test_set:\n",
    "        tweet = instance[0]\n",
    "        sentiment = instance[1]\n",
    "        p = 1/(1 + np.exp(-model(tweet,b,weights)))\n",
    "        p = round(p)\n",
    "        if p != sentiment:\n",
    "            misclassifications += 1\n",
    "    test_acc = 1 - (misclassifications/len(test_set))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the accuracy the best model has on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681958333333333"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(0.25,best_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top and bottom 5 words by weight and value of bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of the bias term b is 0.25.\n",
      "\n",
      "Top 5 words by weight:\n",
      "fuzzball : 1.8636939241280448\n",
      "congratulations : 1.8168852557725164\n",
      "smile : 1.7804523876121507\n",
      "smiling : 1.7748624096021746\n",
      "thankyou : 1.6979606224160717\n",
      "\n",
      "Bottom 5 words by weight:\n",
      "disappointing : -2.740210959584076\n",
      "sad : -2.683452014344879\n",
      "sadly : -2.548252279248958\n",
      "gutted : -2.4814051102306203\n",
      "bummed : -2.3949742841183888\n"
     ]
    }
   ],
   "source": [
    "print(\"The value of the bias term b is 0.25.\")\n",
    "print()\n",
    "print(\"Top 5 words by weight:\")\n",
    "for word,weight in dict(sorted(best_w.items(), key=operator.itemgetter(1), reverse=True)[:5]).items():\n",
    "    print(word,\":\",weight)\n",
    "print()\n",
    "print(\"Bottom 5 words by weight:\")\n",
    "for word,weight in dict(sorted(best_w.items(), key=operator.itemgetter(1))[:5]).items():\n",
    "    print(word,\":\",weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
